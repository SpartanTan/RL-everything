{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y=xA^T=b$\n",
    "Here is a super simple example. $y=ax+b$, where a in this case is 0.8693 and the bias is -0.2126\n",
    "\n",
    "torch.nn.Linear(in_features, out_features, bias=True, device=None, dtype=None)  \n",
    "$y = xA^T+B$\n",
    "Variabels:\n",
    "- weight(torch.Tensor): shape(out_feature, in_feature)\n",
    "- bias: shape(out_feature)\n",
    "\n",
    "example:\n",
    "```python\n",
    "m = nn.Linear(20,30)\n",
    "print(m.weight.shape)\n",
    "```\n",
    "will give (30, 20)\n",
    "So [1x30] = [1*20] *[20 * 30] + [30 *1]  \n",
    "$A^T$ is [20 *30]  \n",
    "A therefore is [30 * 20]  \n",
    "The orthogonal_ make this matrix $A^TA=I$  \n",
    "The gain in the orthogonal_ is multiplied to each element "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1])\n",
      "Parameter containing:\n",
      "tensor([[0.8693]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2126], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Linear(1, 1)\n",
    "\n",
    "print(model.weight.size())\n",
    "print(model.weight)\n",
    "print(model.bias)\n",
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we feed some inputs into this layer. As can be seen from the result, it is exactly doing the calculation of  \n",
    "$y=0.8693x-0.2126$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6567],\n",
      "        [1.5259],\n",
      "        [2.3952],\n",
      "        [3.2644]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor([[1.0], [2.0], [3.0], [4.0]], requires_grad=True)\n",
    "# targets = torch.tensor([[2.0], [4.0], [6.0], [8.0]])\n",
    "predictions = model(inputs)\n",
    "print(predictions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find out the gradient of the sum of the predictions:\n",
    "\n",
    "$\\frac{\\partial prediction}{\\partial weight} = \\frac{\\partial \\sum(predictions)}{\\partial weight}=\n",
    "\\frac{\\partial \\sum(inputs*weights+bias)}{\\partial weight} = \\sum(inputs)$  \n",
    "\n",
    "\n",
    "Also you can check the $\\frac{\\partial f}{ \\partial a}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10.]])\n",
      "tensor([[0.8693],\n",
      "        [0.8693],\n",
      "        [0.8693],\n",
      "        [0.8693]])\n"
     ]
    }
   ],
   "source": [
    "model.zero_grad()\n",
    "predictions.backward(torch.ones_like(predictions))\n",
    "print(model.weight.grad)\n",
    "print(inputs.grad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we do not want the weight to move towards the driection that make the prediction smaller, instead we want to minimize the loss function. So now we can calculate the loss. The expression of loss function is:  \n",
    "\n",
    "$L(y_{pred}, y_{target}) = (1/N) * \\sum (y_{pred_i} - y_{target_i})^2$  \n",
    "\n",
    "$\\frac{\\partial L}{\\partial weight}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.8365, grad_fn=<MseLossBackward0>)\n",
      "tensor([[-18.0241]])\n",
      "tensor([[-0.5839],\n",
      "        [-1.0753],\n",
      "        [-1.5668],\n",
      "        [-2.0582]])\n"
     ]
    }
   ],
   "source": [
    "model.zero_grad()\n",
    "targets = torch.tensor([[2.0], [4.0], [6.0], [8.0]])\n",
    "loss = loss_function(predictions, targets)\n",
    "print(loss)\n",
    "loss.backward()\n",
    "print(model.weight.grad)\n",
    "print(inputs.grad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK. So now I already have the gradient of the weight. This is the direction of increasing the loss, thus we need to use gradient descent to go down.\n",
    "The SGD expression is $weight = weight - lr * gradient$  \n",
    "So that it is\n",
    "$0.8693 - 0.01 * -18.0241 = 1.0495$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[1.0495]], requires_grad=True)\n",
      "tensor([[-18.0241]])\n",
      "tensor([[-0.5839],\n",
      "        [-1.0753],\n",
      "        [-1.5668],\n",
      "        [-2.0582]])\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "optimizer.step()\n",
    "print(model.weight)\n",
    "print(model.weight.grad)\n",
    "print(inputs.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Clear the gradients for the next iteration. Otherwise the gradients will be accumulated to existing gradients.\n",
    "optimizer.zero_grad()\n",
    "print(model.weight.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ros2_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
